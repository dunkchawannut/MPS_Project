{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#The purpose of this script is to clean the news header data by matching the keyword to the Mcdonald dictionary\n",
    "#To do = extract mood of the keyword\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from itertools import chain\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Load Mcdonald'sdictionary\n",
    "LMD = pd.read_excel(\"LoughranMcDonald_MasterDictionary_2014.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#The original file use year instead of flag variable\n",
    "#Change to flag variable 1 = indicate the sentiment\n",
    "LMD.loc[LMD.Negative != 0 , 'Negative'] = 1\n",
    "LMD.loc[LMD.Positive != 0 , 'Positive'] = 1\n",
    "LMD.loc[LMD.Uncertainty != 0 , 'Uncertainty'] = 1\n",
    "LMD.loc[LMD.Litigious != 0 , 'Litigious'] = 1\n",
    "LMD.loc[LMD.Constraining != 0, 'Constraining']=1\n",
    "LMD.loc[LMD.Superfluous != 0 , 'Superfluous'] = 1\n",
    "LMD.loc[LMD.Interesting != 0 , 'Interesting'] = 1\n",
    "LMD.loc[LMD.Modal != 0 , 'Interesting'] = 1\n",
    "LMD.loc[LMD.Irr_Verb != 0 , 'Interesting'] = 1\n",
    "LMD.loc[LMD.Harvard_IV != 0 , 'Interesting'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Change from list of list to list\n",
    "main_word = LMD[[\"Word\"]].values.flatten().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Remove stop words\n",
    "stop_words = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "news_data = pd.read_json(\"WSJ/wsj.json\")\n",
    "#Convert from list of list to list using .str[0]\n",
    "news_data[\"title\"] = news_data[\"title\"].str[0]    \n",
    "news_data[\"category\"] = news_data[\"category\"].str[0]    \n",
    "news_data[\"date\"] = news_data[\"date\"].str[0]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Extract date from the given string#\n",
    "\n",
    "final_date = [] \n",
    "lookup_month = [\"jan\" , \"feb\" , \"mar\" , \"apr\" , \"may\" , \"jun\" , \"jul\" , \"aug\" , \"sep\" , \"oct\" , \"nov\" , \"dec\"]\n",
    "row = news_data.shape[0] \n",
    "track = 1 #just to track progress\n",
    "\n",
    "for i in range(row):\n",
    "    text = news_data[\"date\"][i]\n",
    "    text = text.lower()\n",
    "    \n",
    "    #split by comma (month and day before comma and after comma is year)\n",
    "    temp = text.split(\",\")\n",
    "    \n",
    "    #Get day\n",
    "    day = temp[0][-2:].replace(\"  \", \"\")\n",
    "    \n",
    "    #Get year\n",
    "    year = temp[1][0:5].replace(\" \",\"\")\n",
    "    \n",
    "    #Get month\n",
    "    for m  in lookup_month:\n",
    "        if temp[0].find(m) != -1:\n",
    "            month = m \n",
    "    \n",
    "    '''\n",
    "    #Print process\n",
    "    if i/10000 > track:\n",
    "        print(i)\n",
    "        track = track + 1\n",
    "        \n",
    "    '''\n",
    "    \n",
    "    final_date.append(day + \"-\" + month + \"-\" + year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_score = []\n",
    "Negative_final = []\n",
    "Positive_final = []\n",
    "Uncertainty_final = []\n",
    "Litigious_final = []\n",
    "Constraining_final = []\n",
    "Superfluous_final = []\n",
    "Interesting_final = [] \n",
    "Modal_final = []\n",
    "Irr_Verb_final = []\n",
    "Harvard_IV_final = []\n",
    "\n",
    "track = 1\n",
    "\n",
    "for i in range(row): #For each news header\n",
    "# for i in range(5):\n",
    "    #score = w1+w2+...\n",
    "    data = news_data[\"title\"][i]\n",
    "    accum = 0 \n",
    "    #mood_accum = np.array(10)\n",
    "    #Negative \tPositive \tUncertainty \tLitigious \tConstraining \tSuperfluous \tInteresting \tModal \tIrr_Verb \tHarvard_IV\n",
    "    Negative = 0\n",
    "    Positive = 0\n",
    "    Uncertainty = 0\n",
    "    Litigious = 0 \n",
    "    Constraining = 0\n",
    "    Superfluous = 0 \n",
    "    Interesting = 0 \n",
    "    Modal = 0 \n",
    "    Irr_Verb = 0\n",
    "    Harvard_IV = 0\n",
    "    \n",
    "    tokens = nltk.word_tokenize(data) #Tokenize each news header\n",
    "    tokens = [w.lower() for w in tokens] #Convert to lower case\n",
    "    \n",
    "    stop_words = set(stopwords.words('english')) #Remove stop word\n",
    "    words = [w for w in tokens if not w in stop_words]\n",
    "    \n",
    "    words = [w.upper() for w in words] #Convert to upper case since the dictionary is in uppercase \n",
    "    words = [a for a in words if a in main_word] #Match only those word in the main_Word\n",
    "    \n",
    "    #Calculate score for each news header\n",
    "    #Get word proportion of each matched token\n",
    "    for token in words:\n",
    "        temp_score = LMD.loc[LMD.Word == token,  'Word Proportion'].values\n",
    "        #list of list to list\n",
    "        temp_score = temp_score[0]\n",
    "        \n",
    "        accum = accum + temp_score\n",
    "        #Not a good idea to use numpy vstack in the loop so we will use append with list here\n",
    "        mood = LMD.loc[LMD.Word == token,  ['Negative' , 'Positive' , 'Uncertainty' ,'Litigious' , 'Constraining' , 'Superfluous' , 'Interesting' , 'Modal' , 'Irr_Verb' , 'Harvard_IV'  ]].values[0]\n",
    "        \n",
    "        Negative += mood[0]\n",
    "        Positive += mood[1]\n",
    "        Uncertainty += mood[2]\n",
    "        Litigious += mood[3]\n",
    "        Constraining += mood[4]\n",
    "        Superfluous += mood[5]\n",
    "        Interesting += mood[6]\n",
    "        Modal += mood[7]\n",
    "        Irr_Verb +=  mood[8]\n",
    "        Harvard_IV +=  mood[9]\n",
    "    \n",
    "    \n",
    "    final_score.append(accum)\n",
    "    \n",
    "    Negative_final.append(Negative)\n",
    "    Positive_final.append(Positive)\n",
    "    \n",
    "    Uncertainty_final.append(Uncertainty)\n",
    "    Litigious_final.append(Litigious)\n",
    "    \n",
    "    Constraining_final.append(Constraining)\n",
    "    Superfluous_final.append(Superfluous)\n",
    "    \n",
    "    Interesting_final.append(Interesting)\n",
    "    Modal_final.append(Modal)\n",
    "    \n",
    "    Irr_Verb_final.append(Irr_Verb)\n",
    "    Harvard_IV_final.append(Harvard_IV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#building the feature of the dataset\n",
    "news_data[\"score\"] = final_score\n",
    "news_data[\"Negative_final\"] = Negative_final\n",
    "news_data[\"Positive_final\"] = Positive_final\n",
    "news_data[\"Uncertainty_final\"] = Uncertainty_final\n",
    "news_data[\"Litigious_final\"] = Litigious_final\n",
    "news_data[\"Constraining_final\"] = Constraining_final\n",
    "news_data[\"Superfluous_final\"] = Superfluous_final\n",
    "news_data[\"Interesting_final\"] = Interesting_final\n",
    "news_data[\"Modal_final\"] = Modal_final\n",
    "news_data[\"Irr_Verb_final\"] = Irr_Verb_final\n",
    "news_data[\"Harvard_IV_final\"] = Harvard_IV_final\n",
    "news_data[\"final_date\"] = final_date\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_data_final=news_data.drop(news_data.columns[:3], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s2012=pd.read_csv('score.csv')\n",
    "s2013=pd.read_csv(\"WSJ2013-2018score/score2013.csv\")\n",
    "s2014=pd.read_csv(\"WSJ2013-2018score/score2014.csv\")\n",
    "s2015=pd.read_csv(\"WSJ2013-2018score/score2015.csv\")\n",
    "s2016=pd.read_csv(\"WSJ2013-2018score/score2016.csv\")\n",
    "s2017=pd.read_csv(\"WSJ2013-2018score/score2017.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Constraining_final    False\n",
       "Harvard_IV_final      False\n",
       "Interesting_final     False\n",
       "Irr_Verb_final        False\n",
       "Litigious_final       False\n",
       "Modal_final           False\n",
       "Negative_final        False\n",
       "Positive_final        False\n",
       "Superfluous_final     False\n",
       "Uncertainty_final     False\n",
       "len                    True\n",
       "score                 False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sums.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2017['final_date']=s2017.final_date.str.replace('\\r\\n','')\n",
    "s2017['final_date']=s2017.final_date.str.replace('\\r','')\n",
    "s2017['len']=s2017.final_date.apply(len)\n",
    "s2017=s2017[s2017['len']==11]\n",
    "del s2017['len']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2015['len']=s2015.final_date.apply(len)\n",
    "s2015=s2015[s2015.len != 6]\n",
    "del s2015['len']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sumdata=pd.concat([s2012,s2013,s2014,s2015,s2016,s2017])\n",
    "sums=sumdata.iloc[:,[0,1,2,3,4,5,6,7,8,9,-3,-2]]\n",
    "#final=pd.concat([sums,news_data_final])\n",
    "sums.to_csv('final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    150189\n",
       "1     93741\n",
       "2     32243\n",
       "3      6635\n",
       "4       920\n",
       "5        95\n",
       "6        10\n",
       "Name: Interesting_final, dtype: int64"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sums['Interesting_final'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/admin/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/Users/admin/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/Users/admin/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/Users/admin/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n",
      "/Users/admin/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "sums['Constraining_final'] = sums['Constraining_final'].astype(str) \n",
    "sums['Constraining_final'] = sums['Constraining_final'].replace('2009','1')\n",
    "sums['Constraining_final'] = sums['Constraining_final'].replace('2011','1')\n",
    "sums['Constraining_final'] = sums['Constraining_final'].replace('4018','2')\n",
    "sums['Constraining_final'] = sums['Constraining_final'].replace('6027','3')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sums.to_csv('final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
